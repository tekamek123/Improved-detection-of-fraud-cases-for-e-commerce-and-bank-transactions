{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Initialize JS visualization for interactive plots\n",
        "shap.initjs()\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up paths\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "data_dir = project_root / 'data' / 'processed'\n",
        "models_dir = project_root / 'models'\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Data directory: {data_dir}\")\n",
        "print(f\"Models directory: {models_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "print(\"Loading processed data...\")\n",
        "X_test = pd.read_csv(data_dir / 'X_test_processed.csv')\n",
        "y_test = pd.read_csv(data_dir / 'y_test_processed.csv').values.ravel()\n",
        "\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Test set class distribution:\")\n",
        "print(pd.Series(y_test).value_counts())\n",
        "print(f\"\\nFraud rate: {y_test.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best model (Random Forest)\n",
        "print(\"Loading best model...\")\n",
        "best_model = joblib.load(models_dir / 'best_model_random_forest.pkl')\n",
        "print(f\"Model loaded: {type(best_model).__name__}\")\n",
        "print(f\"Model parameters:\")\n",
        "print(best_model.get_params())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Importance Baseline\n",
        "\n",
        "Extract and visualize the built-in feature importance from the Random Forest model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature importance from Random Forest\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_test.columns,\n",
        "    'importance': best_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Top 20 Most Important Features (Random Forest Built-in):\")\n",
        "print(\"=\"*60)\n",
        "print(feature_importance.head(20).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top 10 most important features\n",
        "top_10_features = feature_importance.head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(range(len(top_10_features)), top_10_features['importance'].values[::-1])\n",
        "plt.yticks(range(len(top_10_features)), top_10_features['feature'].values[::-1])\n",
        "plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
        "plt.title('Top 10 Most Important Features (Random Forest Built-in)', fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTop 10 Features:\")\n",
        "for idx, row in top_10_features.iterrows():\n",
        "    print(f\"{row['feature']:30s}: {row['importance']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. SHAP Analysis\n",
        "\n",
        "Generate SHAP values to understand how each feature contributes to individual predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create SHAP explainer\n",
        "# For Random Forest, we use TreeExplainer which is optimized for tree-based models\n",
        "print(\"Creating SHAP TreeExplainer...\")\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "print(\"SHAP explainer created successfully!\")\n",
        "\n",
        "# Note: Computing SHAP values for the entire test set can be slow\n",
        "# We'll use a sample for faster computation, but keep enough for meaningful analysis\n",
        "sample_size = min(1000, len(X_test))\n",
        "X_test_sample = X_test.sample(n=sample_size, random_state=42)\n",
        "y_test_sample = y_test[X_test_sample.index]\n",
        "\n",
        "print(f\"\\nComputing SHAP values for {sample_size} samples...\")\n",
        "shap_values = explainer.shap_values(X_test_sample)\n",
        "\n",
        "# For binary classification, shap_values is a list [values_for_class_0, values_for_class_1]\n",
        "# We're interested in class 1 (fraud)\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values_fraud = shap_values[1]  # Class 1 (fraud)\n",
        "else:\n",
        "    shap_values_fraud = shap_values\n",
        "\n",
        "print(f\"SHAP values computed. Shape: {shap_values_fraud.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Summary Plot (Global Feature Importance)\n",
        "print(\"Generating SHAP Summary Plot...\")\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(shap_values_fraud, X_test_sample, plot_type=\"bar\", show=False)\n",
        "plt.title(\"SHAP Global Feature Importance (Bar Plot)\", fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Summary Plot (Detailed - shows feature values and their impact)\n",
        "print(\"Generating detailed SHAP Summary Plot...\")\n",
        "plt.figure(figsize=(12, 10))\n",
        "shap.summary_plot(shap_values_fraud, X_test_sample, show=False)\n",
        "plt.title(\"SHAP Summary Plot (Feature Value Impact)\", fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions for the sample\n",
        "y_pred_sample = best_model.predict(X_test_sample)\n",
        "y_pred_proba_sample = best_model.predict_proba(X_test_sample)[:, 1]\n",
        "\n",
        "# Create a DataFrame for easier analysis\n",
        "results_df = pd.DataFrame({\n",
        "    'true_label': y_test_sample,\n",
        "    'predicted_label': y_pred_sample,\n",
        "    'predicted_proba': y_pred_proba_sample\n",
        "}, index=X_test_sample.index)\n",
        "\n",
        "# Identify cases\n",
        "true_positives = results_df[(results_df['true_label'] == 1) & (results_df['predicted_label'] == 1)]\n",
        "false_positives = results_df[(results_df['true_label'] == 0) & (results_df['predicted_label'] == 1)]\n",
        "false_negatives = results_df[(results_df['true_label'] == 1) & (results_df['predicted_label'] == 0)]\n",
        "\n",
        "print(\"Case Distribution:\")\n",
        "print(f\"True Positives (Correctly identified fraud): {len(true_positives)}\")\n",
        "print(f\"False Positives (Legitimate flagged as fraud): {len(false_positives)}\")\n",
        "print(f\"False Negatives (Missed fraud): {len(false_negatives)}\")\n",
        "print(f\"True Negatives: {len(results_df[(results_df['true_label'] == 0) & (results_df['predicted_label'] == 0)])}\")\n",
        "\n",
        "# Select representative cases\n",
        "if len(true_positives) > 0:\n",
        "    tp_idx = true_positives.index[0]  # First TP\n",
        "    tp_sample_idx = X_test_sample.index.get_loc(tp_idx)\n",
        "    print(f\"\\nSelected True Positive case: Index {tp_idx} (Sample index: {tp_sample_idx})\")\n",
        "    print(f\"  Predicted probability: {true_positives.iloc[0]['predicted_proba']:.4f}\")\n",
        "else:\n",
        "    tp_sample_idx = None\n",
        "    print(\"\\nNo True Positives found in sample\")\n",
        "\n",
        "if len(false_positives) > 0:\n",
        "    fp_idx = false_positives.index[0]  # First FP\n",
        "    fp_sample_idx = X_test_sample.index.get_loc(fp_idx)\n",
        "    print(f\"\\nSelected False Positive case: Index {fp_idx} (Sample index: {fp_sample_idx})\")\n",
        "    print(f\"  Predicted probability: {false_positives.iloc[0]['predicted_proba']:.4f}\")\n",
        "else:\n",
        "    fp_sample_idx = None\n",
        "    print(\"\\nNo False Positives found in sample\")\n",
        "\n",
        "if len(false_negatives) > 0:\n",
        "    fn_idx = false_negatives.index[0]  # First FN\n",
        "    fn_sample_idx = X_test_sample.index.get_loc(fn_idx)\n",
        "    print(f\"\\nSelected False Negative case: Index {fn_idx} (Sample index: {fn_sample_idx})\")\n",
        "    print(f\"  Predicted probability: {false_negatives.iloc[0]['predicted_proba']:.4f}\")\n",
        "else:\n",
        "    fn_sample_idx = None\n",
        "    print(\"\\nNo False Negatives found in sample\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Force Plot for True Positive (Correctly identified fraud)\n",
        "if tp_sample_idx is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\"SHAP Force Plot: TRUE POSITIVE (Correctly Identified Fraud)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"True Label: Fraud (1)\")\n",
        "    print(f\"Predicted Label: Fraud (1)\")\n",
        "    print(f\"Predicted Probability: {y_pred_proba_sample[tp_sample_idx]:.4f}\")\n",
        "    print(\"\\nThis plot shows how each feature pushed the prediction toward fraud:\")\n",
        "    \n",
        "    # Create force plot\n",
        "    shap.force_plot(\n",
        "        explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
        "        shap_values_fraud[tp_sample_idx],\n",
        "        X_test_sample.iloc[tp_sample_idx],\n",
        "        matplotlib=True,\n",
        "        show=False\n",
        "    )\n",
        "    plt.title(\"SHAP Force Plot: True Positive (Correctly Identified Fraud)\", \n",
        "              fontsize=12, fontweight='bold', pad=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print top contributing features\n",
        "    feature_contributions = pd.DataFrame({\n",
        "        'feature': X_test_sample.columns,\n",
        "        'shap_value': shap_values_fraud[tp_sample_idx],\n",
        "        'feature_value': X_test_sample.iloc[tp_sample_idx].values\n",
        "    }).sort_values('shap_value', key=abs, ascending=False)\n",
        "    \n",
        "    print(\"\\nTop 10 Features Contributing to Fraud Prediction:\")\n",
        "    print(feature_contributions.head(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"No True Positive case available for visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Force Plot for False Positive (Legitimate flagged as fraud)\n",
        "if fp_sample_idx is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\"SHAP Force Plot: FALSE POSITIVE (Legitimate Flagged as Fraud)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"True Label: Legitimate (0)\")\n",
        "    print(f\"Predicted Label: Fraud (1)\")\n",
        "    print(f\"Predicted Probability: {y_pred_proba_sample[fp_sample_idx]:.4f}\")\n",
        "    print(\"\\nThis plot shows why a legitimate transaction was incorrectly flagged:\")\n",
        "    \n",
        "    # Create force plot\n",
        "    shap.force_plot(\n",
        "        explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
        "        shap_values_fraud[fp_sample_idx],\n",
        "        X_test_sample.iloc[fp_sample_idx],\n",
        "        matplotlib=True,\n",
        "        show=False\n",
        "    )\n",
        "    plt.title(\"SHAP Force Plot: False Positive (Legitimate Flagged as Fraud)\", \n",
        "              fontsize=12, fontweight='bold', pad=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print top contributing features\n",
        "    feature_contributions = pd.DataFrame({\n",
        "        'feature': X_test_sample.columns,\n",
        "        'shap_value': shap_values_fraud[fp_sample_idx],\n",
        "        'feature_value': X_test_sample.iloc[fp_sample_idx].values\n",
        "    }).sort_values('shap_value', key=abs, ascending=False)\n",
        "    \n",
        "    print(\"\\nTop 10 Features Contributing to Incorrect Fraud Prediction:\")\n",
        "    print(feature_contributions.head(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"No False Positive case available for visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Force Plot for False Negative (Missed fraud)\n",
        "if fn_sample_idx is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\"SHAP Force Plot: FALSE NEGATIVE (Missed Fraud)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"True Label: Fraud (1)\")\n",
        "    print(f\"Predicted Label: Legitimate (0)\")\n",
        "    print(f\"Predicted Probability: {y_pred_proba_sample[fn_sample_idx]:.4f}\")\n",
        "    print(\"\\nThis plot shows why a fraudulent transaction was missed:\")\n",
        "    \n",
        "    # Create force plot\n",
        "    shap.force_plot(\n",
        "        explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
        "        shap_values_fraud[fn_sample_idx],\n",
        "        X_test_sample.iloc[fn_sample_idx],\n",
        "        matplotlib=True,\n",
        "        show=False\n",
        "    )\n",
        "    plt.title(\"SHAP Force Plot: False Negative (Missed Fraud)\", \n",
        "              fontsize=12, fontweight='bold', pad=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print top contributing features\n",
        "    feature_contributions = pd.DataFrame({\n",
        "        'feature': X_test_sample.columns,\n",
        "        'shap_value': shap_values_fraud[fn_sample_idx],\n",
        "        'feature_value': X_test_sample.iloc[fn_sample_idx].values\n",
        "    }).sort_values('shap_value', key=abs, ascending=False)\n",
        "    \n",
        "    print(\"\\nTop 10 Features Contributing to Incorrect Legitimate Prediction:\")\n",
        "    print(feature_contributions.head(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"No False Negative case available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Interpretation: SHAP vs Built-in Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate mean absolute SHAP values (global importance)\n",
        "mean_abs_shap = pd.DataFrame({\n",
        "    'feature': X_test_sample.columns,\n",
        "    'mean_abs_shap': np.abs(shap_values_fraud).mean(axis=0)\n",
        "}).sort_values('mean_abs_shap', ascending=False)\n",
        "\n",
        "print(\"Top 20 Features by Mean Absolute SHAP Value:\")\n",
        "print(\"=\"*60)\n",
        "print(mean_abs_shap.head(20).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare SHAP importance with built-in feature importance\n",
        "comparison = pd.merge(\n",
        "    feature_importance.rename(columns={'importance': 'rf_importance'}),\n",
        "    mean_abs_shap.rename(columns={'mean_abs_shap': 'shap_importance'}),\n",
        "    on='feature',\n",
        "    how='outer'\n",
        ").fillna(0)\n",
        "\n",
        "# Normalize both to 0-1 scale for comparison\n",
        "comparison['rf_importance_norm'] = comparison['rf_importance'] / comparison['rf_importance'].max()\n",
        "comparison['shap_importance_norm'] = comparison['shap_importance'] / comparison['shap_importance'].max()\n",
        "\n",
        "# Get top 20 for visualization\n",
        "comparison_top20 = comparison.head(20).sort_values('shap_importance', ascending=True)\n",
        "\n",
        "# Create comparison plot\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "y_pos = np.arange(len(comparison_top20))\n",
        "\n",
        "ax.barh(y_pos - 0.2, comparison_top20['rf_importance_norm'].values, 0.4, \n",
        "        label='Random Forest Built-in', alpha=0.8, color='steelblue')\n",
        "ax.barh(y_pos + 0.2, comparison_top20['shap_importance_norm'].values, 0.4, \n",
        "        label='SHAP Mean |Value|', alpha=0.8, color='coral')\n",
        "\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(comparison_top20['feature'].values)\n",
        "ax.set_xlabel('Normalized Importance', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Feature Importance Comparison: Random Forest vs SHAP (Top 20)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nComparison Summary:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Correlation between RF importance and SHAP importance: {comparison['rf_importance_norm'].corr(comparison['shap_importance_norm']):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify Top 5 Drivers of Fraud Predictions\n",
        "print(\"=\"*60)\n",
        "print(\"TOP 5 DRIVERS OF FRAUD PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nBased on SHAP Analysis (Mean Absolute SHAP Values):\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "top_5_shap = mean_abs_shap.head(5)\n",
        "for idx, (_, row) in enumerate(top_5_shap.iterrows(), 1):\n",
        "    print(f\"{idx}. {row['feature']:30s} - Mean |SHAP|: {row['mean_abs_shap']:.4f}\")\n",
        "\n",
        "print(\"\\nBased on Random Forest Built-in Importance:\")\n",
        "print(\"-\"*60)\n",
        "top_5_rf = feature_importance.head(5)\n",
        "for idx, (_, row) in enumerate(top_5_rf.iterrows(), 1):\n",
        "    print(f\"{idx}. {row['feature']:30s} - Importance: {row['importance']:.4f}\")\n",
        "\n",
        "# Find common features\n",
        "common_top5 = set(top_5_shap['feature']) & set(top_5_rf['feature'])\n",
        "print(f\"\\nCommon features in both top 5: {len(common_top5)}\")\n",
        "if common_top5:\n",
        "    print(f\"Features: {', '.join(common_top5)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Surprising or Counterintuitive Findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze surprising findings\n",
        "print(\"=\"*60)\n",
        "print(\"SURPRISING OR COUNTERINTUITIVE FINDINGS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find features with high SHAP importance but low RF importance (and vice versa)\n",
        "comparison['importance_diff'] = abs(comparison['rf_importance_norm'] - comparison['shap_importance_norm'])\n",
        "comparison['shap_higher'] = comparison['shap_importance_norm'] > comparison['rf_importance_norm'] + 0.1\n",
        "comparison['rf_higher'] = comparison['rf_importance_norm'] > comparison['shap_importance_norm'] + 0.1\n",
        "\n",
        "print(\"\\n1. Features with Higher SHAP Importance than RF Importance:\")\n",
        "print(\"   (These features may have complex interactions)\")\n",
        "shap_higher_features = comparison[comparison['shap_higher']].sort_values('shap_importance', ascending=False).head(10)\n",
        "for _, row in shap_higher_features.iterrows():\n",
        "    print(f\"   - {row['feature']:30s} | SHAP: {row['shap_importance_norm']:.3f} | RF: {row['rf_importance_norm']:.3f}\")\n",
        "\n",
        "print(\"\\n2. Features with Higher RF Importance than SHAP Importance:\")\n",
        "print(\"   (These features may have more consistent effects)\")\n",
        "rf_higher_features = comparison[comparison['rf_higher']].sort_values('rf_importance', ascending=False).head(10)\n",
        "for _, row in rf_higher_features.iterrows():\n",
        "    print(f\"   - {row['feature']:30s} | RF: {row['rf_importance_norm']:.3f} | SHAP: {row['shap_importance_norm']:.3f}\")\n",
        "\n",
        "# Analyze feature interactions by looking at SHAP values distribution\n",
        "print(\"\\n3. Features with High Variability in SHAP Values:\")\n",
        "print(\"   (These features have context-dependent effects)\")\n",
        "shap_std = pd.DataFrame({\n",
        "    'feature': X_test_sample.columns,\n",
        "    'shap_std': shap_values_fraud.std(axis=0),\n",
        "    'shap_mean_abs': np.abs(shap_values_fraud).mean(axis=0)\n",
        "})\n",
        "shap_std['cv'] = shap_std['shap_std'] / (shap_std['shap_mean_abs'] + 1e-10)  # Coefficient of variation\n",
        "high_variability = shap_std.nlargest(10, 'cv')\n",
        "for _, row in high_variability.iterrows():\n",
        "    print(f\"   - {row['feature']:30s} | CV: {row['cv']:.3f} | Mean |SHAP|: {row['shap_mean_abs']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Business Recommendations\n",
        "\n",
        "Based on SHAP analysis, provide actionable recommendations for fraud prevention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze key features for business recommendations\n",
        "print(\"=\"*80)\n",
        "print(\"BUSINESS RECOMMENDATIONS BASED ON SHAP ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get feature statistics for top important features\n",
        "top_features_analysis = []\n",
        "for feature in top_5_shap['feature'].head(5):\n",
        "    fraud_values = X_test_sample[y_test_sample == 1][feature]\n",
        "    legitimate_values = X_test_sample[y_test_sample == 0][feature]\n",
        "    \n",
        "    top_features_analysis.append({\n",
        "        'feature': feature,\n",
        "        'fraud_mean': fraud_values.mean(),\n",
        "        'fraud_median': fraud_values.median(),\n",
        "        'legitimate_mean': legitimate_values.mean(),\n",
        "        'legitimate_median': legitimate_values.median(),\n",
        "        'difference': fraud_values.mean() - legitimate_values.mean()\n",
        "    })\n",
        "\n",
        "analysis_df = pd.DataFrame(top_features_analysis)\n",
        "print(\"\\nFeature Statistics for Top 5 Fraud Drivers:\")\n",
        "print(analysis_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recommendation 1: Time-Based Verification\n",
        "\n",
        "**SHAP Insight**: `time_since_signup` is one of the top drivers of fraud predictions.\n",
        "\n",
        "**Recommendation**: \n",
        "Transactions occurring within **X hours of signup** should receive additional verification steps.\n",
        "\n",
        "**Implementation**:\n",
        "- Calculate time between signup and purchase\n",
        "- Flag transactions with `time_since_signup < threshold` for manual review\n",
        "- Apply stricter verification (2FA, phone verification) for new accounts\n",
        "\n",
        "**Expected Impact**: Reduce false negatives by catching fraudsters who act quickly after account creation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate threshold for time_since_signup\n",
        "if 'time_since_signup' in X_test_sample.columns:\n",
        "    fraud_time = X_test_sample[y_test_sample == 1]['time_since_signup']\n",
        "    legitimate_time = X_test_sample[y_test_sample == 0]['time_since_signup']\n",
        "    \n",
        "    # Use percentile-based threshold\n",
        "    threshold_24h = 24  # 24 hours\n",
        "    threshold_48h = 48  # 48 hours\n",
        "    \n",
        "    fraud_below_24h = (fraud_time < threshold_24h).mean()\n",
        "    legitimate_below_24h = (legitimate_time < threshold_24h).mean()\n",
        "    \n",
        "    print(f\"Fraud transactions within 24 hours of signup: {fraud_below_24h:.2%}\")\n",
        "    print(f\"Legitimate transactions within 24 hours of signup: {legitimate_below_24h:.2%}\")\n",
        "    print(f\"\\nRecommended threshold: {threshold_24h} hours\")\n",
        "    print(f\"Rationale: {fraud_below_24h:.1%} of fraud cases occur within this window\")\n",
        "else:\n",
        "    print(\"'time_since_signup' feature not found in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recommendation 2: Transaction Velocity Monitoring\n",
        "\n",
        "**SHAP Insight**: Transaction frequency features (`transactions_last_24h`, `transactions_last_7d`, `transactions_last_30d`) are key fraud indicators.\n",
        "\n",
        "**Recommendation**: \n",
        "Implement real-time transaction velocity monitoring with automatic flagging for suspicious patterns.\n",
        "\n",
        "**Implementation**:\n",
        "- Monitor number of transactions per user in rolling time windows (24h, 7d, 30d)\n",
        "- Set dynamic thresholds based on user's historical behavior\n",
        "- Flag accounts with sudden spikes in transaction frequency\n",
        "- Combine with amount-based rules (e.g., multiple high-value transactions in short time)\n",
        "\n",
        "**Expected Impact**: Catch fraudsters who make multiple fraudulent transactions quickly, reducing both false negatives and financial losses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze transaction velocity patterns\n",
        "velocity_features = ['transactions_last_24h', 'transactions_last_7d', 'transactions_last_30d']\n",
        "available_velocity = [f for f in velocity_features if f in X_test_sample.columns]\n",
        "\n",
        "if available_velocity:\n",
        "    print(\"Transaction Velocity Analysis:\")\n",
        "    print(\"=\"*60)\n",
        "    for feature in available_velocity:\n",
        "        fraud_vel = X_test_sample[y_test_sample == 1][feature]\n",
        "        legitimate_vel = X_test_sample[y_test_sample == 0][feature]\n",
        "        \n",
        "        print(f\"\\n{feature}:\")\n",
        "        print(f\"  Fraud - Mean: {fraud_vel.mean():.2f}, Median: {fraud_vel.median():.2f}, Max: {fraud_vel.max():.2f}\")\n",
        "        print(f\"  Legitimate - Mean: {legitimate_vel.mean():.2f}, Median: {legitimate_vel.median():.2f}, Max: {legitimate_vel.max():.2f}\")\n",
        "        \n",
        "        # Suggest threshold (e.g., 95th percentile of legitimate)\n",
        "        threshold = legitimate_vel.quantile(0.95)\n",
        "        fraud_above_threshold = (fraud_vel > threshold).mean()\n",
        "        print(f\"  Suggested threshold (95th percentile of legitimate): {threshold:.2f}\")\n",
        "        print(f\"  {fraud_above_threshold:.1%} of fraud cases exceed this threshold\")\n",
        "else:\n",
        "    print(\"Transaction velocity features not found in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recommendation 3: Geolocation-Based Risk Scoring\n",
        "\n",
        "**SHAP Insight**: Country and IP-based features contribute significantly to fraud predictions.\n",
        "\n",
        "**Recommendation**: \n",
        "Implement geolocation-based risk scoring with country-level fraud rate monitoring.\n",
        "\n",
        "**Implementation**:\n",
        "- Map IP addresses to countries (already implemented)\n",
        "- Calculate country-specific fraud rates\n",
        "- Flag transactions from high-risk countries\n",
        "- Combine with device fingerprinting (device_id) for additional verification\n",
        "- Monitor for VPN/proxy usage patterns\n",
        "\n",
        "**Expected Impact**: Reduce fraud from known high-risk regions while minimizing false positives through multi-factor verification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze country-based patterns (if country features exist)\n",
        "country_features = [col for col in X_test_sample.columns if 'country' in col.lower() or 'Country' in col]\n",
        "\n",
        "if country_features:\n",
        "    print(\"Country-Based Risk Analysis:\")\n",
        "    print(\"=\"*60)\n",
        "    for feature in country_features[:5]:  # Limit to first 5 country features\n",
        "        if X_test_sample[feature].dtype in ['int64', 'float64']:\n",
        "            fraud_country = X_test_sample[y_test_sample == 1][feature]\n",
        "            legitimate_country = X_test_sample[y_test_sample == 0][feature]\n",
        "            \n",
        "            print(f\"\\n{feature}:\")\n",
        "            print(f\"  Fraud - Mean: {fraud_country.mean():.2f}, Median: {fraud_country.median():.2f}\")\n",
        "            print(f\"  Legitimate - Mean: {legitimate_country.mean():.2f}, Median: {legitimate_country.median():.2f}\")\n",
        "else:\n",
        "    print(\"Country features not found in dataset\")\n",
        "    print(\"Note: Country information may be encoded in other features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recommendation 4: Device and Browser Pattern Analysis\n",
        "\n",
        "**SHAP Insight**: Device and browser features show significant importance in fraud detection.\n",
        "\n",
        "**Recommendation**: \n",
        "Monitor device and browser usage patterns for anomaly detection.\n",
        "\n",
        "**Implementation**:\n",
        "- Track device_id usage patterns (multiple accounts from same device)\n",
        "- Monitor browser type and version for suspicious patterns\n",
        "- Flag accounts with frequent device/browser changes\n",
        "- Implement device fingerprinting for persistent tracking\n",
        "\n",
        "**Expected Impact**: Identify fraudsters using multiple accounts or compromised devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Recommendation 5: Purchase Value and User Profile Analysis\n",
        "\n",
        "**SHAP Insight**: Purchase value and user demographics (age, sex) contribute to fraud predictions.\n",
        "\n",
        "**Recommendation**: \n",
        "Implement value-based and profile-based risk scoring.\n",
        "\n",
        "**Implementation**:\n",
        "- Flag transactions significantly above user's historical average purchase value\n",
        "- Monitor age-related patterns (very young or very old accounts with high-value transactions)\n",
        "- Combine purchase value with transaction velocity for enhanced detection\n",
        "- Use user profile consistency checks (e.g., age vs. purchase patterns)\n",
        "\n",
        "**Expected Impact**: Catch fraudsters making unusually high-value transactions or using inconsistent profiles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze purchase value patterns\n",
        "value_features = [col for col in X_test_sample.columns if 'purchase_value' in col.lower() or 'value' in col.lower()]\n",
        "\n",
        "if value_features:\n",
        "    print(\"Purchase Value Analysis:\")\n",
        "    print(\"=\"*60)\n",
        "    for feature in value_features[:3]:  # Limit to first 3 value features\n",
        "        if X_test_sample[feature].dtype in ['int64', 'float64']:\n",
        "            fraud_value = X_test_sample[y_test_sample == 1][feature]\n",
        "            legitimate_value = X_test_sample[y_test_sample == 0][feature]\n",
        "            \n",
        "            print(f\"\\n{feature}:\")\n",
        "            print(f\"  Fraud - Mean: ${fraud_value.mean():.2f}, Median: ${fraud_value.median():.2f}, Max: ${fraud_value.max():.2f}\")\n",
        "            print(f\"  Legitimate - Mean: ${legitimate_value.mean():.2f}, Median: ${legitimate_value.median():.2f}, Max: ${legitimate_value.max():.2f}\")\n",
        "            \n",
        "            # Calculate percentile thresholds\n",
        "            threshold_95 = legitimate_value.quantile(0.95)\n",
        "            fraud_above_threshold = (fraud_value > threshold_95).mean()\n",
        "            print(f\"  95th percentile threshold: ${threshold_95:.2f}\")\n",
        "            print(f\"  {fraud_above_threshold:.1%} of fraud cases exceed this threshold\")\n",
        "else:\n",
        "    print(\"Purchase value features not found in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Next Steps\n",
        "\n",
        "### Key Findings:\n",
        "1. **Top 5 Fraud Drivers** (from SHAP analysis):\n",
        "   - Identified through mean absolute SHAP values\n",
        "   - These features have the strongest impact on fraud predictions\n",
        "\n",
        "2. **SHAP vs Built-in Importance**:\n",
        "   - Generally aligned, but SHAP reveals feature interactions\n",
        "   - Some features show context-dependent effects\n",
        "\n",
        "3. **Individual Prediction Insights**:\n",
        "   - True Positives: Correctly identified fraud cases\n",
        "   - False Positives: Legitimate transactions incorrectly flagged\n",
        "   - False Negatives: Missed fraud cases requiring attention\n",
        "\n",
        "### Business Recommendations Summary:\n",
        "1. **Time-Based Verification**: Flag transactions within 24-48 hours of signup\n",
        "2. **Transaction Velocity Monitoring**: Real-time monitoring of transaction frequency\n",
        "3. **Geolocation Risk Scoring**: Country-based fraud rate monitoring\n",
        "4. **Device/Browser Analysis**: Pattern-based anomaly detection\n",
        "5. **Value and Profile Analysis**: Purchase value and user profile consistency checks\n",
        "\n",
        "### Next Steps:\n",
        "- Implement recommended rules in production system\n",
        "- A/B test the impact of new verification steps\n",
        "- Monitor false positive rates to ensure good user experience\n",
        "- Continuously update risk thresholds based on new fraud patterns\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
